{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30279bd3-481b-4ca7-a20b-350d8334ad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dbc6f3-6222-40ba-9895-08f5be51afad",
   "metadata": {},
   "source": [
    "# Underfitting and overfitting\n",
    "## Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8545282a-bb82-4e09-b47e-26fa3212593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('../data/titanic.csv')\n",
    "\n",
    "# prepare data\n",
    "titanic = titanic.drop(columns=['Name']) # drop the column 'Name'\n",
    "is_F = (titanic['Sex']=='female') # array of True and False\n",
    "titanic['Sex'] = is_F.astype(int) # 1 = female, 0 = male\n",
    "\n",
    "# split to train and tests\n",
    "train = titanic.sample(frac=0.8) # 80% rows for training\n",
    "test = titanic.drop(index=train.index)\n",
    "\n",
    "# split to X and y\n",
    "y_train = train['Survived']\n",
    "X_train = train.drop(columns=['Survived'])\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "y_test = test['Survived']\n",
    "X_test = test.drop(columns=['Survived']) \n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bd0f41-6d58-403d-b504-4d8a2961970a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "T2 = tree.DecisionTreeClassifier(max_depth=      )\n",
    "T20 = tree.DecisionTreeClassifier(max_depth=      )\n",
    "\n",
    "T2.fit(X_train, y_train)\n",
    "T20.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a30552a-b474-47d3-90e1-d2a351fed4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize = (10, 10))\n",
    "p = tree.plot_tree(T2, \n",
    "                   filled=True, \n",
    "                   feature_names=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5b26e7-df3a-4d7d-84cc-13a1bc71b4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize = (10, 10))\n",
    "p = tree.plot_tree(T20, \n",
    "                   filled=True, \n",
    "                   feature_names=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac859ee-aa11-4beb-bb17-df49e5884840",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('max_depth 2')\n",
    "print('Train score:',T2.score(    ,   ))\n",
    "print('Test score:',T2.score(   ,  ))\n",
    "print()\n",
    "print('max_depth 20')\n",
    "print('Train score:',T20.score(   ,  ))\n",
    "print('Test score:',T20.score(   ,   ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb67e30-708b-4f65-9e33-eb536c833402",
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = range(1, 31)\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for depth in depths:\n",
    "    T = tree.DecisionTreeClassifier(max_depth=      , criterion='gini')\n",
    "    T.fit(   ,   )\n",
    "    train_scores.append(T.score(   ,   ))\n",
    "    test_scores.append(T.score(   ,   ))\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "sns.scatterplot(x=depths, y=train_scores, label='train')\n",
    "sns.scatterplot(x=depths, y=test_scores, label='test')\n",
    "ax.set_xlabel('Depth of tree')\n",
    "ax.set_ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb593a1-01bb-42f2-8c27-9e5cc9e7d463",
   "metadata": {},
   "source": [
    "## Polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10360291-9df6-4303-a5c3-8bdf9b7adaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# controls random number generation\n",
    "# always get the same data\n",
    "np.random.seed(1234) \n",
    "\n",
    "# true model is linear with a = 1 and b = 1\n",
    "a = 1\n",
    "b = 1\n",
    "\n",
    "n_points = 100\n",
    "\n",
    "X = np.random.rand(n_points)\n",
    "Y = a*X + b + 0.2*np.random.randn(n_points) # final term is random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eb9762",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "ax.plot([0,1], [1, 2], color = \"black\", label = \"true model\")\n",
    "ax.scatter(X, Y, label = \"data\")\n",
    "ax.set(xlabel='X', ylabel='Y')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0364827",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={'Y': Y, 'X': X})\n",
    "train = df.sample(frac=0.8) # 80% rows for training\n",
    "test = df.drop(index=train.index) # rest of rows for testing\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d3a5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['Y']\n",
    "X_train = train.drop(columns=['Y'])\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "y_test = test['Y']\n",
    "X_test = test.drop(columns=['Y']) \n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff6461a-b3e3-4027-b51d-81dd6441056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree),\n",
    "                         LinearRegression(**kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c887771-9df8-4aa6-9866-6151d6104ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1 = PolynomialRegression(      ).fit(X_train, y_train)\n",
    "lr20 = PolynomialRegression(      ).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3826b175-b120-498c-84b6-7b8a767edf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_inputs = pd.DataFrame(data={'X': np.linspace(0.01, 1, 1000)})\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "ax.plot(prediction_inputs, lr1.      (prediction_inputs), color = \"red\", label = \"linear\")\n",
    "ax.plot(prediction_inputs, lr20.      (prediction_inputs), color = \"green\", label = \"degree 20\")\n",
    "\n",
    "ax.scatter(X_train, y_train, marker='*', label = \"train data\")\n",
    "ax.scatter(X_test, y_test, label = \"test data\")\n",
    "\n",
    "ax.set(xlabel='X', ylabel='Y')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae3362f-9daa-490f-9351-e98c8bdee4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('degree 1 (linear)')\n",
    "print('Train score:', lr1.score(  ,    ))\n",
    "print('Test score:', lr1.score(   ,   ))\n",
    "print()\n",
    "print('degree 20')\n",
    "print('Train score:', lr20.score(   ,   ))\n",
    "print('Test score:', lr20.score(   ,   ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55708826-c48d-4e25-b254-e5a02ace6446",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = range(1, 31)\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for degree in degrees:\n",
    "    lr = PolynomialRegression(      ).fit(   ,   )\n",
    "    train_scores.append(lr.score(  ,    ))\n",
    "    test_scores.append(lr.score(   ,   ))\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "sns.scatterplot(x=degrees, y=train_scores, label='train')\n",
    "sns.scatterplot(x=degrees, y=test_scores, label='test')\n",
    "ax.set_xlabel('Degree of polynomial regression')\n",
    "ax.set_ylabel('$R^2$ score')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
