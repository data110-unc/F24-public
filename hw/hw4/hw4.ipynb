{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3e99ef",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw4.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac1aa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "pd.set_option(\"future.no_silent_downcasting\", True)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649f6dd1",
   "metadata": {},
   "source": [
    "## <u>Name:</u> [Your name] and (your onyen)\n",
    "\n",
    "Names and Onyens of fellow students you discussed Homework4 problems and ideas:\n",
    "\n",
    "- Students: \n",
    "\n",
    "We encourage discussing ideas and brainstorming with your peers, but the final text, code, and comments in this homework assignment MUST be 100% written by you as mentioned in syllabus.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55c8fcf",
   "metadata": {},
   "source": [
    "## Problem 1.  (15 points) Just how old are you?\n",
    "Suppose you are asked to provide information about the **age of permanent residents of North Carolina**, so you decide to obtain age data for **100 people**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f25f0c",
   "metadata": {},
   "source": [
    "### **Problem 1.1 (4 points)** \n",
    "Initially, you ask the age of the **first 100 people you meet on campus**.  \n",
    "1. What is this type of sampling called? Pick **one** closest and most specific answer.\n",
    "3. What are potential biases that could result from this sampling approach?  Name **at least two**.  \n",
    "4. Would you expect this to be a representative sample of North Carolina residents?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce6fac0",
   "metadata": {},
   "source": [
    "*Write your answers here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f29ff7",
   "metadata": {},
   "source": [
    "### **Problem 1.2 (4 points)** \n",
    "You decide to look up the **proportions of race/ethnicity** for North Carolina permanent residents. You calculate the corresponding **proportions of 100**, then collect data again by wandering campus and asking the age of exactly that many people of each race/ethnicity.  \n",
    "\n",
    "For example, the [2020 US Census](https://www.census.gov/library/stories/state-by-state/north-carolina-population-change-between-census-decade.html) says the four largest NC race and ethnicity groups are White alone 62%, Black alone 12%, Hispanic 19%, and Asian alone 6%. So you would ask the age of the first 62 White people you meet, the first 12 Black people you meet, and so on.\n",
    "\n",
    "1. What type of sampling is this? Pick **one** closest and most specific answer.\n",
    "2. Would you expect it to be more or less representative than your previous data from Problem 1.1?  \n",
    "3. What are the most significant biases that would remain?  Name **at least two**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0508cabb",
   "metadata": {},
   "source": [
    "*Write your answers here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114e92e0",
   "metadata": {},
   "source": [
    "### **Problem 1.3 (2 points)** \n",
    "Alternatively, suppose you get access to full census data for all residents of the state of North Carolina that includes age as an attribute.  You take the age of the **first 100 rows of the table** and drop the rest.  What potential concerns do you have with this approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f879f8fa",
   "metadata": {},
   "source": [
    "*Write your answers here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a906b07",
   "metadata": {},
   "source": [
    "### **Problem 1.4 (4 points)** \n",
    "Finally, you decide to take **100 random samples from the census data** table.\n",
    "1. What type of sampling is this? Pick **one** closest and most specific answer.\n",
    "2. Would you expect this to be a representative sample of North Carolina residents?\n",
    "3. Do you think it matters if you allow replacement for this sampling?  Why or why not?\n",
    "4. If the census data is in a table named `nc_people` that has a row for every person, write code that uses pandas to randomly sample 100 people from `nc_people` and put them in a new table named `nc_people_100`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7765d2e8",
   "metadata": {},
   "source": [
    "*Write your answers here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7dbba4",
   "metadata": {},
   "source": [
    "### **Problem 1.5 (1 point)** \n",
    "Which of the following is an example of sampling?\n",
    "1. Enumerating all the possible outcomes of drawing 1 card from a deck\n",
    "2. Counting the number of planets in our solar system\n",
    "3. Surveying a piece of property to mark its boundaries\n",
    "4. Asking people in your class who sit next to you their favorite Pokemon "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b29b38e",
   "metadata": {},
   "source": [
    "*Write your answers here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40bda5b",
   "metadata": {},
   "source": [
    "## Problem 2. Loaded question (30 points)\n",
    "\n",
    "In this problem, you'll be analyzing the fairness of a 6-sided die.\n",
    "\n",
    "A street vendor asks you if you'd like to play a game.  The game is:\n",
    "* pay \\$10 to roll a 6-sided die 3 times\n",
    "* if any of those rolls is a 6 he pays you $11.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a9d686",
   "metadata": {},
   "source": [
    "### **Problem 2.1 (3 points) Probability**\n",
    "For these three questions, **assume the die is fair**.  (We'll reconsider this dubious assumption in the next section.)\n",
    "1) What are your chances of rolling **at least one 6** in a game? (show how you calculate this)\n",
    "\n",
    "**Hint**: It might be easier to calculate the complementary probability of this event, then subtract that from 1.\n",
    "\n",
    "2) To the nearest cent, what is the **expected value** of your profit or loss if you play the game 10 times?\n",
    "4) If you play the game 100 times, are you guaranteed to win **at least one** of the games?  (again, assuming the die is fair)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69882011",
   "metadata": {},
   "source": [
    "*Write your answers here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367c0603",
   "metadata": {},
   "source": [
    "### **Problem 2.2 (4 points) Hypothesis Testing**\n",
    "You decide to play the game 20 times, and out of your 60 total rolls of the die, you roll a 6 **four times**.  You start to suspect something is not right, and you wonder if perhaps the die is NOT fair.  In particular, you feel that there might be **less than fair chance** of rolling a 6, even though the street vendor insists it is fair. You decide to conduct a hypothesis test.\n",
    "\n",
    "1) State the null hypothesis for this situation.  Remember, you'll need to be able to \"simulate under the null\".\n",
    "2) State the alternative hypothesis.\n",
    "3) Which of the following statistics would you be appropriate for evaluating these hypotheses?\n",
    "* a) cost to play the game\n",
    "* b) number of 5's rolled\n",
    "* c) proportion of 6's rolled\n",
    "* d) total number of rolls\n",
    "4) What is the value of this statistic for the 20 games you played?  Assign it to `measured_statistic1` in the provided cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8316a116",
   "metadata": {},
   "source": [
    "*Write your answers to 1-4 here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fab772",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assign the value of the statistic for the 20 games here\n",
    "measured_statistic1 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1129ca05",
   "metadata": {},
   "source": [
    "### **Problem 2.3 (10 points) Simulating under the null**\n",
    "In this problem, you'll be writing code to simulate the test statistic for 30 rolls, and you'll run that simulation 1000 times. \n",
    "\n",
    "**Hint**: Refer back to demo code from lectures as well as lab9 to complete this problem.\n",
    "\n",
    "#### Problem 2.3.1 (2 points) \n",
    "First, write a function named `sample_die()` that takes an argument `num_rolls` and returns a list containing that many simulated 6-sided die rolls.  Import whatever Python package you need to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efea4850",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "...\n",
    "def sample_die(num_rolls):\n",
    "    rolls = ...\n",
    "    # This is sampling from uniform distribution\n",
    "    return list(rolls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56b46f5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Problem 2.3.2 (2 points)\n",
    "Next, write code to simulate 1000 times the test statistic for 60 die rolls, and store the test statistic in a table named `statistic1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f3075b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "statistic1 = pd.DataFrame(columns=['test statistic'])\n",
    "\n",
    "for simulation in range(1000):\n",
    "    # finish the code below\n",
    "    simulated_rolls = pd.DataFrame(sample_die(60), columns=['roll']) # create a 1-column table of randomly simulated rolls\n",
    "    # sixes is an array of True or False. True if roll is 6, False otherwise.\n",
    "    sixes = ...\n",
    "    # calculate the statistic for this simulated data using sixes\n",
    "    sim_t1 = ...\n",
    "    statistic1.loc[len(statistic1)] = [sim_t1] # add simulated result to end of table\n",
    "statistic1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334fcf41",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Problem 2.3.3 (2 points)\n",
    "Plot the empirical distribution of your statistics simulated under the null.  Plot a vertical line for the value of the measured statistic for your actual games.  Label your plot using the parameter `label=`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c84c0a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. Plot empirical distribution of t1 (under the null)\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "# write your code here\n",
    "...\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca9e570",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Problem 2.3.4 (1 point)\n",
    "Looking at the shape of your distribution, what type of distribution is your simulation data, approximately? We're referring to the distribution of the statistics simulated under the null."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1085bd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*Write your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8f9c0b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Problem 2.3.5 (2 points) \n",
    "Write code to compute the p-value from the `statistic1` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d09c97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p_value1 = ...\n",
    "p_value1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5173d1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Problem 2.3.6 (1 point)\n",
    "Does your simulation provide evidence against the null?  (yes or no)  If so, is the evidence statistically significant?  Is it extremely statistically significant?  Explain the convention you are using to answer these questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80d80f4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*Write your answers here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97988d60",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### **Problem 2.4 (4 points) Hypothesis testing revisited**\n",
    "Instead of investigating if there is a less than fair chance of rolling a 6 like you just did, now evaluate if there is an **unfair chance** of rolling a 6 (either more likely or less likely than fair).\n",
    "\n",
    "1) State the null hypothesis for this situation.\n",
    "2) State the alternative hypothesis.\n",
    "3) Which of the following statistics would you be appropriate for evaluating these hypotheses?\n",
    "* a) number of 6's rolled in a row\n",
    "* b) abs(proportion of 6's rolled - 1/6)\n",
    "* c) abs(proportion of 6's rolled + 1/6)\n",
    "* d) abs(total number of rolls)\n",
    "4) What is the value of this statistic for the 20 games you played?  Assign it to `measured_statistic2` in the provided cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a32650c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*Write your answers to 1-4 here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f11c1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assign your measured statistic here\n",
    "measured_statistic2 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe697287",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### **Problem 2.5 (8 points) Simulating under the null revisited**\n",
    "\n",
    "#### Problem 2.5.1 (3 points)\n",
    "Now, write code to simulate 1000 times this new test statistic for 60 die rolls, and store the results in a table named `statistic2`.  You can use the same `sample_die()` function you wrote before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b73af7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "statistic2 = pd.DataFrame(columns=['test statistic'])\n",
    "\n",
    "for simulation in range(1000):\n",
    "    # finish the code below\n",
    "    simulated_rolls = ...\n",
    "    sixes = ...\n",
    "    sim_t2 = ...\n",
    "    statistic2.loc[len(statistic2)] = [sim_t2] # add simulated result to end of table\n",
    "statistic2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27c63c9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Problem 2.5.2 (2 points)\n",
    "Plot the empirical distribution of your statistics simulated under the null.  Plot a vertical line for the value of the measured statistic for your actual games.  Label your plot using the parameter `label=`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dd0381",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "# write your code here\n",
    "...\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8bc1ce",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "\n",
    "#### Problem 2.5.3 (2 points)\n",
    "Write code to compute the p-value from the `statistic2` table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6a273c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p_value2 = ...\n",
    "p_value2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99470a6",
   "metadata": {},
   "source": [
    "#### Problem 2.5.4 (1 points)\n",
    "Does your simulation provide evidence against the null?  (yes or no)  If so, is the evidence statistically significant?  Is it extremely statistically significant?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809b1aba",
   "metadata": {},
   "source": [
    "*Write your answers here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8a476d",
   "metadata": {},
   "source": [
    "### **Problem 2.6 Optimization (1 point)**\n",
    "In class, we simulated two test statistics inside a single loop using the same set of samples, and we could have done that here too.  Why is it okay to do that for this problem?  What advantage would it offer?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779ed1ce",
   "metadata": {},
   "source": [
    "*Write your answers here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4365c87",
   "metadata": {},
   "source": [
    "## Problem 3. You need a loan?  Hmm, let me decide (20 points)\n",
    "Many of you have expressed interest in financial technology, so for this problem you will be using historic data from a bank about whether or not people were granted loans.  You'll be using this data to create a predictor for whether the bank would grant loans to future applicants.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9740632",
   "metadata": {},
   "source": [
    "### **Problem 3.1 Data Preparation (4 points)**\n",
    "First, load the loan data into a table named `loan_data_raw`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a81178",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_raw = pd.read_csv('loan_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ab4670",
   "metadata": {},
   "source": [
    "#### Problem 3.1.1 (1 point)\n",
    "We don't need the `Loan_ID` column, so drop that column and store the resulting table in `loan_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c7b8fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loan_data= ...\n",
    "loan_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a27d681",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Problem 3.1.2 (1 point)\n",
    "Some of the values are missing from the table, so write the code to drop rows from `loan_data` that have any missing values, and store the result in `loan_data_clean`.\n",
    "\n",
    "**Hint**: We did this in lab10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c137132",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loan_data_clean= ...\n",
    "loan_data_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464b992e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Problem 3.1.3 (2 points)\n",
    "You'll be using functions from `scikit-learn`, which don't know how to handle text values like `Male` or `Female` or `Yes` or `No`, so you'll have to turn them into numbers. For the `Gender` and `Married` columns, use boolean indexing to do this by assigning 0 for `Male` and 1 for `Female` and 0 for `No` and 1 for `Yes` (just like we did in lecture demo).  Some of the code is already provided, you fill in the rest.  \n",
    "\n",
    "**WARNING:** running this cell twice will set `Gender` and `Married` to all zeroes!  (think about why this is so)  If you do this accidentally, you can always just run the cell above that drops values to re-create `loan_data_clean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591478b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "is_Female = ...\n",
    "loan_data_clean['Gender'] = is_Female.astype(int)\n",
    "is_Yes = (loan_data_clean['Married']=='Yes')\n",
    "loan_data_clean['Married'] = ...\n",
    "loan_data_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9375f9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Problem 3.1.4 (0 points)\n",
    "Copy the code below that will do the same thing (a faster way) for the remaining columns.\n",
    "```Python\n",
    "loan_data_clean['Loan_Status'] = loan_data_clean.Loan_Status.replace({'N': 0, 'Y': 1})\n",
    "loan_data_clean['Property_Area'] = loan_data_clean.Property_Area.replace({'Rural':0, 'Urban':1, 'Semiurban':2})\n",
    "loan_data_clean['Education'] = loan_data_clean.Education.replace({'Graduate':0, 'Not Graduate':1})\n",
    "loan_data_clean['Dependents'] = loan_data_clean.Dependents.replace({'0':0, '1':1,'2':2,'3+':3})\n",
    "loan_data_clean = loan_data_clean.astype(float)\n",
    "loan_data_clean\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc566fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copy code here.\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d47c78",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### **Problem 3.2 Train and Test, part 1 (10 points)**\n",
    "Next, you'll be creating your training set and your test set.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fde591c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Problem 3.2.1 (2 points)\n",
    "As we did in class and lab, create the training data from 80% of `loan_data_clean` by using random sampling.  The create the test set by dropping from `loan_data_clean` all the rows that are in the training set.  We set the random seed below to make the sampling reproducible so that everyone will be working with the same training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d69d0b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(420) # this makes the sampling reproducible, so everyone has same train and test\n",
    "train_loan = ...\n",
    "test_loan = ...\n",
    "print(train_loan.shape, test_loan.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a536b597",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Problem 3.2.2 (2 points)\n",
    "You will be trying to predict `Loan_Status` from all the other data.  Create the approriate `X` and `y` tables for both the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd58828",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_loan = ...\n",
    "y_train_loan = ...\n",
    "X_test_loan = ...\n",
    "y_test_loan = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f7c665",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Problem 3.2.3 (2 points)\n",
    "Finally, use the `DecisionTreeClassifier` to create a decision tree to use for prediction.  Finish the code to print the scores of the classifier on the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33215495",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "T = DecisionTreeClassifier(max_depth=3)\n",
    "T.fit(X_train_loan, y_train_loan)\n",
    "train_score = ...\n",
    "test_score = ...\n",
    "print('Score on train:', train_score)\n",
    "print('Score on test:', test_score)\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize = (20, 20))\n",
    "p = plot_tree(T, filled = True, feature_names = X_train_loan.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2bf837",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Problem 3.2.4 (1 points)\n",
    "Looking at the decision tree, which feature is the most important for predicting if a loan would be approved? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb2991f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*Write your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8261f4de",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Problem 3.2.5 (1 points)\n",
    "Next, we're going to gather some data for creating decision trees of different maximum tree depths.  Finish the code below to call the decision tree classifier with different maximum depths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652ef10e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_scores=[]\n",
    "test_scores=[]\n",
    "r=range(1,13)\n",
    "for i in r:\n",
    "    T = ...\n",
    "    T.fit(X_train_loan, y_train_loan)\n",
    "    train_scores.append(T.score(X_train_loan, y_train_loan))\n",
    "    test_scores.append(T.score(X_test_loan, y_test_loan))\n",
    "fig, ax = plt.subplots(1)\n",
    "sns.lineplot(x=r,y=train_scores,label='train')\n",
    "sns.lineplot(x=r,y=test_scores,label='test')\n",
    "ax.set_ylabel('Prediction score', fontsize=14)\n",
    "ax.set_xlabel('Max tree depth', fontsize=14)\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b074c912",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52bc515a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Problem 3.2.6 (2 points)\n",
    "Observe the generated plot.\n",
    "1. Does the accuracy improve for the **train** set as the maximum tree depth increases?\n",
    "2. Does the accuracy improve for the **test** set as the maximum tree depth increases?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3528d954",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### **Problem 3.3 Train and Test, part 2 (6 points)**\n",
    "You may have noticed that the `Credit_History` feature dominates the loan decision process (which makes sense!)  Using just this feature (max tree depth == 1), the prediction score is over 80%.  But what if you didn't have access to that feature?  How well could you predict what the bank would do?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de60ce43",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Problem 3.3.1 (1 point)\n",
    "Finish the code below to drop the `Credit_History` column from your train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252c3b8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X2_train_loan = ...\n",
    "X2_test_loan = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2446d4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Problem 3.3.2 (1 point)\n",
    "Finish the code below to create a new classifier fit to the new train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c26feed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "T2 = DecisionTreeClassifier(max_depth=3)\n",
    "# write your code here\n",
    "...\n",
    "\n",
    "print('Score on train:', T2.score(X2_train_loan, y_train_loan))\n",
    "print('Score on test:', T2.score(X2_test_loan, y_test_loan))\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize = (20, 20))\n",
    "p = plot_tree(T2, filled = True, feature_names = X2_train_loan.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35a6c88",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Problem 3.3.3 (1 point)\n",
    "How do the new scores for the train and test data compare to the previous scores that you printed?  Explain why you might have expected this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e648ae2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*Write your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9fd159",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Problem 3.3.4 (1 points)\n",
    "Once again, finish the code to gather prediction scores at different max tree depths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1b2610",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_scores=[]\n",
    "test_scores=[]\n",
    "r=range(1,13)\n",
    "for i in r:\n",
    "    T = DecisionTreeClassifier(max_depth=i)\n",
    "    # write your code here\n",
    "    ...\n",
    "    train_scores.append(T.score(X2_train_loan, y_train_loan))\n",
    "    test_scores.append(T.score(X2_test_loan, y_test_loan))\n",
    "fig, ax = plt.subplots(1)\n",
    "sns.lineplot(x=r,y=train_scores,label='train')\n",
    "sns.lineplot(x=r,y=test_scores,label='test')\n",
    "ax.set_ylabel('Prediction score', fontsize=14)\n",
    "ax.set_xlabel('Max tree depth', fontsize=14)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935b18bf",
   "metadata": {},
   "source": [
    "#### Problem 3.3.5 (1 point)\n",
    "You should notice that increasing the tree depth dramatically improves the prediction score for the train set.  This is because without `Credit_History`, there is no one primary feature correlated to the outcome, so we need more features to explain the loan decision data.  At roughly what tree depth is the predictor able to predict as well for the train data as the previous predictor did using just `Credit_History`? (i.e. > 80%)?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34c82a8",
   "metadata": {},
   "source": [
    "*Write your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1d9a74",
   "metadata": {},
   "source": [
    "#### Problem 3.3.6 (2 points)\n",
    "You should see that for the test data, the predictor never gets near to the 80% mark.  No matter how deep the tree, the prediction score for the test data does not improve the same way as it did for the train data.  Why is this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e930bfe0",
   "metadata": {},
   "source": [
    "*Write your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c65f1ae",
   "metadata": {},
   "source": [
    "## Problem 4. Parkinsons progression detection (20 points)\n",
    "\n",
    "We will reproduce some of the qualitative results from \n",
    "the following paper, which I've downloaded for you in the same folder:\n",
    "\n",
    "    A. Tsanas, M. A. Little, P. E. McSharry and L. O. Ramig, \"Accurate Telemonitoring of Parkinson's Disease Progression by Noninvasive Speech Tests,\" in IEEE Transactions on Biomedical Engineering, vol. 57, no. 4, pp. 884-893, April 2010, doi: 10.1109/TBME.2009.2036000.\n",
    "\n",
    "The Parkinsons Telemonitoring dataset was downloaded from https://archive.ics.uci.edu/dataset/189/parkinsons+telemonitoring.\n",
    "\n",
    "**It is not necessary for you to read or understand the paper in order to complete this problem. You only need to look at the Tables and Figures in the paper that I point to.**\n",
    "\n",
    "For context, this dataset is composed of a range of biomedical voice measurements from 42 people with early-stage Parkinson's disease recruited to a six-month trial of a telemonitoring device for remote symptom progression monitoring. The recordings were automatically captured in the patient's homes.\n",
    "    \n",
    "Physical test observations are mapped to a metric specifically designed to follow disease progression, typically the unified Parkinson’s disease rating scale (UPDRS) that reflects the presence and severity of symptoms (but does not quantify their underlying causes). For untreated patients, the **total UPDRS spans the range 0–176**, with 0 representing healthy state and 176 representing total disabilities, and consists of three sections: 1) mentation, behavior, and mood; 2) activities of daily living; and 3) motor. The **motor UPDRS ranges from 0 to 108**, with 0 denoting symptom free and 108 denoting severe motor impairment, and encompasses tasks such as speech, facial expression, tremor, and rigidity. \n",
    "\n",
    "Columns in the table contain subject number, subject age, subject gender, time interval from baseline recruitment date, motor UPDRS, total UPDRS, and 16 biomedical voice measures. Each row corresponds to one of 5,875 voice recording from these individuals. **The main aim is to predict the motor and total UPDRS scores from the 16 voice measures.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed95847-74c3-46a1-be43-3a94bd0994e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "parkinsons = pd.read_csv('parkinsons_updrs.csv')\n",
    "parkinsons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc724583-9dec-46f1-8ab0-6633e5bfaa8f",
   "metadata": {},
   "source": [
    "### **Problem 4.1 (2 points) Concepts of machine learning**\n",
    "\n",
    "Given the data format and the description above,\n",
    "- Is this more of a **regression** problem or a **classification** problem? Pick one closest answer.\n",
    "- What do the **samples** correspond to, and how many are there?\n",
    "- What are the **target variables (labels, y)**, and how many are there?\n",
    "- What are the **predictor variables (features, X)**, and how many are there?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c26ca4-6f8d-4c0d-a0c5-a4201691bb23",
   "metadata": {},
   "source": [
    "[Write your answer here!]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566cc0fe-013c-4590-82da-d822b5aefd3e",
   "metadata": {},
   "source": [
    "### **Problem 4.2 (5 points) Exploring correlations**\n",
    "\n",
    "Open the paper pdf file and scroll down to page 887, Table 1. It looks scary, but all it's doing is calculating the **correlations** between each of the voice features with the UPDRS scores. We'll recreate this table step by step.\n",
    "\n",
    "#### Step 1 (1 point)\n",
    "\n",
    "Drop the columns `subject#`, `age`, `sex`, `test_time` and save the resulting table to a new variable `parkinsons_small`. Your new table should be of size (5875, 18)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020d884d-791f-4057-a7e1-64b9c6ce4d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "parkinsons_small = parkinsons.drop(             )\n",
    "print(parkinsons_small.shape)\n",
    "parkinsons_small.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d4e4dc-4216-4c74-9f53-0d77663c999b",
   "metadata": {},
   "source": [
    "#### Step 2 (0 point, it's just copy pasting)\n",
    "\n",
    "Copy and run the following code, which calculates the correlation between each pairs of columns in `parkinsons_small`. Your new table should be of size (18, 18).\n",
    "\n",
    "```Python\n",
    "corrs = parkinsons_small.corr(method='spearman')\n",
    "print(corrs.shape)\n",
    "corrs\n",
    "```\n",
    "\n",
    "How to read the table: The correlation between `Jitter(%)` and `total_UPDRS` is 0.129237.\n",
    "\n",
    "Out of scope for DATA110 but just in case you're curious: There are a few mathematical definitions of how to calculate correlation, and Pearson's and Spearman's are two of the most popular methods. The main difference is that Spearman's cares about the ranking of the values, and not the raw values. So it has fewer assumptions on the data than Pearson's and can handle outliers better. But the way the correlation values are interpreted are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6b1206-df40-4fc2-b466-1617a9962084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d205ff3-193c-4b68-b931-9159461ec5c0",
   "metadata": {},
   "source": [
    "#### Step 3 (2 points)\n",
    "\n",
    "Since we're only interested in the correlations with the UPDRS scores, \n",
    "\n",
    "1. Keep only the columns `motor_UPDRS`,`total_UPDRS` and save the new table to `corrs_table1`.\n",
    "2. Within the table `corrs_table1`, drop the rows with index `motor_UPDRS`,`total_UPDRS` and save the new table to `corrs_table1` (overwrite it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85af80fd-bd07-4581-b40d-6ad269bf0a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3\n",
    "corrs_table1 = corrs.filter(            )\n",
    "corrs_table1 = corrs_table1.drop(            )\n",
    "corrs_table1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed738a91-4227-44d7-8449-f7a5042e7505",
   "metadata": {},
   "source": [
    "#### Step 4 (2 points) Interpretation\n",
    "\n",
    "Compare what you have with the numbers in Table 1, and check if they are **roughly** the same. \n",
    "\n",
    "**Note**: The numbers won't be exactly the same, because 5923 recordings are analyzed in the paper, but we only have access to 5875 of them. \n",
    "\n",
    "Question: What are your interpretations of these values? Do any of the biomedical voice variables seem highly correlated with the Parkinson's scores? Which variable do you think would be the most important in predicting UPDRS? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19986338-1566-450e-afbc-7e27989010a6",
   "metadata": {},
   "source": [
    "[Write your answer here!]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81022142-667f-47be-87d1-e59d5fe3d424",
   "metadata": {},
   "source": [
    "### **Problem 4.3 (5 points) Prepare data for ML**\n",
    "\n",
    "Now comes the actual prediction! We will train and test a **linear regression** model to predict motor_UPDRS from the 16 voice variables. In other words, we are assuming that the motor_UPDRS scores are **approximately** equal to\n",
    "\n",
    "c1\\*Jitter(%) + c2\\*Jitter(Abs) + c3\\*Jitter:RAP + ... + c16\\*PPE\n",
    "\n",
    "for some set of coefficients (c1, c2, c3, ..., c16). And when we train or fit a linear regression model, we are looking for the best set of coefficients that describes the training dataset. When we test the model, we compare the model's predictions with the actual motor_UPDRS scores in the test dataset. If any of this sounds foreign to you, now would be a good time to review the past few lectures.\n",
    "\n",
    "#### Problem 4.3.1 (1 point)\n",
    "\n",
    "In an ideal world, we would train our model on the entire dataset, collect data from new patients, then test it on the new data. However, this is obviously not feasible in this case. In cases like this, most people randomly split the *existing* samples into train and test, and \"pretend\" like the samples in the test set are actually coming from future patients.\n",
    "\n",
    "We can split the data by patients or by recordings. The authors of this paper chose to split by recordings. \n",
    "\n",
    "Fill in the blank such that this sentence describes what the code does:\n",
    "\n",
    "    We will randomly put __1__% of the ___2____ into the __3___ set, and put the remaining __2_____ into the ____3___ set.\n",
    "\n",
    "- Options for 1: number between 0 and 100\n",
    "- Options for 2: rows or columns\n",
    "- Options for 3: train or test\n",
    "\n",
    "The corresponding code:\n",
    "\n",
    "```Python\n",
    "train = parkinsons_small.sample(frac=0.9)\n",
    "test = parkinsons_small.drop(index=train.index)\n",
    "```\n",
    "\n",
    "And then copy and run the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a034c7-477c-4281-8e03-1abe2efbadad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8798f538-9b35-44e2-8032-72ffeb5b7692",
   "metadata": {},
   "source": [
    "#### Problem 4.3.2 (4 point)\n",
    "\n",
    "Given your knowledge of what predictor variables and target variables are, create the following four variables: `X_train`, `y_train`, `X_test`, `y_test`. They are derived from tables `train` and `test`.\n",
    "\n",
    "Here's one way to check your answer:\n",
    "```Python\n",
    "print(X_train.shape, y_train.shape)\n",
    "    (5288, 16) (5288,)\n",
    "print(X_test.shape, y_test.shape)\n",
    "    (587, 16) (587,)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986101be-d23a-47a8-b106-f0847fc3ca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfe2462-2a85-4eb5-b8ed-d0010ec43903",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e07824-6f51-4855-a951-ce4afc1bac1e",
   "metadata": {},
   "source": [
    "### **Problem 4.4 (2 points) Train and test model**\n",
    "\n",
    "Copy the code, fill in the blanks (i.e., call with appropriate parameters), and run the code in the next cell.\n",
    "\n",
    "```Python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression(fit_intercept=False)\n",
    "lr.fit(..., ...)\n",
    "print(lr.score(..., ...))\n",
    "\n",
    "coefs = pd.DataFrame(lr.coef_, \n",
    "                     index=lr.feature_names_in_, \n",
    "                    columns=['Motor UPDRS LR coefficients'])\n",
    "coefs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868796cf-1ddd-4a75-8faa-49d3a7e9c0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9a255f4-3d3e-4a7d-8d63-809f01e6d31f",
   "metadata": {},
   "source": [
    "### **Problem 4.5 (3 points) Analyze model results**\n",
    "\n",
    "- (1 point) Given the $R^2$ score that is printed out, do you think this linear regression model is a good predictive model of motor_UPDRS or not?\n",
    "- (2 points) Out of the 16 features, which one(s) are deemed the most *important* or *useful* at predicting motor_UPDRS according to the model? Comment on both the magnitude and direction (negative vs. positive) of the coefficient values and what that means in the context of the problem we're interested in. Are they the same variables you mentioned in Problem 4.2 (based on correlations)? You are welcome to compare your numbers with the reulsts in Table 3 (first column), but not required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2e4656-46ea-40ea-ad95-2f5bb3107ac0",
   "metadata": {},
   "source": [
    "[Write your answers here!]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cd29af-98df-4d61-8c59-eec98bc1946d",
   "metadata": {},
   "source": [
    "### **Problem 4.6 (3 points) Repeating the experiment multiple times**\n",
    "\n",
    "You might say - but Harlin, this is only based on a specific train/test split. What if it just so happened that this set of samples leads to this result? How can we trust our interpretations are generally true? \n",
    "\n",
    "You are absolutely right! That's why the authors of this paper repeated this 1000 times to create Table 3. \n",
    "\n",
    "Fill in the missing parts of the code below (you shouldn't have to write new code, just copy paste from earlier problems). \n",
    "\n",
    "```Python\n",
    "coefs = pd.DataFrame([], columns=lr.feature_names_in_)\n",
    "\n",
    "for i in range(1000):\n",
    "    train = parkinsons_small.sample(frac=0.9)\n",
    "    test = parkinsons_small.drop(train.index)\n",
    "\n",
    "    #####\n",
    "    # Add four lines of code here that creates X_train, y_train, X_test, y_test. \n",
    "    #####\n",
    "    \n",
    "    lr = LinearRegression(fit_intercept=False)\n",
    "    # fill in the parameters here\n",
    "    lr.fit(..., ...)\n",
    "\n",
    "    coefs.loc[len(coefs)] = lr.coef_\n",
    "\n",
    "coefs.mean()\n",
    "```\n",
    "\n",
    "Then tell us, **how did your analysis on the importance of each feature change?** If it didn't change, that's is also okay.\n",
    "\n",
    "\n",
    "**Note**: Again, you won't get the same numbers as Table 3 because we don't have access to the full dataset, and there is some randomness involved. But my coefficients except for Jitter (%) looks *qualitatively* similar (I get a 40-ish number for Jitter (%) instead of a -80-ish number, which is odd)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a52b3f2-6a17-4f13-b965-4f7cad8e24ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22e5d3e-cd00-4ada-8fa5-1e9d85dfd325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should give you pretty box plots once you're done with the previous question.\n",
    "sns.boxplot(coefs, orient='h')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a8614e-6864-4b89-8637-a3bb193dd7d1",
   "metadata": {},
   "source": [
    "## Problem 5. Random walk (15 points)\n",
    "\n",
    "In this problem, we’ll simulate the simple random walk, perhaps the most important discrete-time stochastic process. Random walks are commonly used to model phenomena in physics, chemistry, biology, and finance. \n",
    "\n",
    "In the simple random walk, we flip a coin at each timestep. If heads, we move foward one step; if tails, we move backwards. For example, if our beginning position is 0 and we move three steps backwards, our position is -3.\n",
    "\n",
    "### **Problem 5.1 (8 points)** \n",
    "\n",
    "Write a `random_walk` function to simulate a random walk. Your function should:\n",
    "\n",
    "- Take int `n` as input, which represents the number of coin flips or steps.\n",
    "- Also take int `start` as input, which is the beginning position. This has a default value of 0.\n",
    "- Lastly take `weights` as input, which is a list of two numbers that indicate the probabilities of flipping heads and tails, respectively. This has a default value of [0.5, 0.5] (fair coin).\n",
    "- Return `positions`, which is a list of integers. It keeps track of your position at each time step, including the beginning position indicated by `start`. It should have `n`+1 numbers in it.\n",
    "\n",
    "**Hint**: To simulate a fair coin toss, try running the following cell multiple times. You don’t have to use \"H\" and \"T\" when using this function – can you think of a more useful choice set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd4c753-64f5-4650-8a35-0352dd60ca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.choices([\"H\", \"T\"], weights=[0.4, 0.6], k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77df5f1-be4f-4a52-b9f4-93274b0130cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "# write your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac672101-3bea-4b4b-9687-8d93cdc7c406",
   "metadata": {},
   "source": [
    "Before moving on to the next step, make sure to check your code by running the function with different arguments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08607806-aa56-4500-a4d1-1a914cb62c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One way to check your code.\n",
    "# Make sure to try different parameters.\n",
    "positions = random_walk(20)\n",
    "print(positions[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e26727f-1462-47f3-9b3d-bd222423837b",
   "metadata": {},
   "source": [
    "I've written some visualization code for you. Run the following two cells to check that your code works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e8c8d1-fe73-4e38-8cee-3d6dfc2933e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_random_walk(positions, lower_bound=0, upper_bound=40):\n",
    "    fig, ax = plt.subplots(1, figsize=(12, 8))\n",
    "    sns.lineplot(positions)\n",
    "    ax.set_xlabel('Timestep', fontsize=14)\n",
    "    ax.set_ylabel('Position', fontsize=14)\n",
    "    ax.axhline(lower_bound, linestyle=':', color='r', label='Broke')\n",
    "    ax.axhline(upper_bound, linestyle=':', color='k', label='Quit while ahead')\n",
    "    \n",
    "    ax.set_title('Random Walk', fontsize=20)\n",
    "    ax.legend(fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b465c25-e870-4476-b46e-68ee3b9f2061",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = random_walk(1000)\n",
    "plot_random_walk(positions, -20, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b56eb90-55d6-40c9-8e59-45493da8aac9",
   "metadata": {},
   "source": [
    "### **Problem 5.2 (2 points)**\n",
    "\n",
    "Let's consider this scenario. \n",
    "\n",
    "You go to Vegas with \\$20 in your pocket, and play a game at the casino. The dealer says, \"I'll flip this fair coin 500 times, and if it lands heads, I'll give you a dollar. But if it lands tails, you'll have to give me a dollar.\"\n",
    "\n",
    "Because you're smart, you decide that once you earn 10 additional dollars from this game, you'll walk away and quit while you're ahead.\n",
    "\n",
    "Call `random_walk` and `plot_random_walk` with appropriate parameters that fit this story.\n",
    "\n",
    "\n",
    "**Hint**: What would your `positions` correspond to in this story? \n",
    "\n",
    "**Hint**: You're \"broke\" if you lose all \\$20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67cabd0-c624-4814-aff8-7a67d330c47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = random_walk(        ) \n",
    "plot_random_walk(          ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbb3c92-fa5d-447c-94cd-fe5a76f012a7",
   "metadata": {},
   "source": [
    "Did you win? Did you lose? Not broke but also not able to quit while ahead? Obviously, you're not able to continue playing once you lose all your money, so we're asking whether you hit the red line ('broke') first or the black line ('quit while ahead') first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3893cb0-edc1-4113-a6ac-63d37e43abae",
   "metadata": {},
   "source": [
    "[Write your answer here!]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018ef60e-fed9-4471-a462-03195f5000f2",
   "metadata": {},
   "source": [
    "### **Problem 5.3 (5 points)**\n",
    "\n",
    "Uh oh, it turns out the dealer was lying to us :( The coin was not fair! The coin was slightly biased against you, only turning up heads 41% of the time.\n",
    "\n",
    "Call the functions again with the correct parameters given this new information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5a992f-4a75-4910-8736-4afca5d5ec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = random_walk(            )\n",
    "plot_random_walk(           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9e6288-2eb1-4caf-9d7a-5af4e1fbfef3",
   "metadata": {},
   "source": [
    "Run this unfair game 10 times, and tell us what happened. Did you win or lose? There's no need to show us the plots; just run the same cell 10 times and keep track of your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8062049-6577-421b-a75a-0292045bc0ff",
   "metadata": {},
   "source": [
    "Double click on this markdown cell to edit the table:\n",
    "\n",
    "| Game    | Outcome |\n",
    "| -------- | ------- |\n",
    "| 1 |  |\n",
    "| 2 |  |\n",
    "| 3 |  |\n",
    "| 4 |  |\n",
    "| 5 |  |\n",
    "| 6 |  |\n",
    "| 7 |  |\n",
    "| 8 |  |\n",
    "| 9 |  |\n",
    "| 10 |  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63e036c-a69c-4f3d-b640-34cec014af22",
   "metadata": {},
   "source": [
    "You probably noticed that even though the coin was only slightly biased against you and 41% sounds like decent odds, you're much more likely to lose than win. This is a phenomenon called **gambler's ruin**. You can read about it more in the [Wikipedia article](https://en.wikipedia.org/wiki/Gambler%27s_ruin) or [this lecture notes](https://web.mit.edu/neboat/Public/6.042/randomwalks.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabe50ac-ac5a-4f16-b7e5-62f370d4d27a",
   "metadata": {},
   "source": [
    "## Extra credit (1 extra credit point)\n",
    "\n",
    "How many hours did you spend on each of HW1, HW2, HW3, and HW4? Your answer won't affect your grade."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2e9a96-8776-45b5-8c32-d5d76dff5a09",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43a3f9f6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "Submit zip file and PDF to Gradescope Homework4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4a460e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False, run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb4e168",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
